{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = True\n",
    "SEED = 1\n",
    "BATCH_SIZE = 1\n",
    "LOG_INTERVAL = 10\n",
    "EPOCHS = 50\n",
    "VALIDATION_SPLIT = .2\n",
    "ZDIMS = 60\n",
    "ENCODER_DIMS = 6000\n",
    "DECODER_DIMS = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if CUDA else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader = torch.utils.data.DataLoader(\n",
    "#    datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "#    batch_size=BATCH_SIZE, shuffle=True, **kwargs\n",
    "\n",
    "#)\n",
    "\n",
    "#test_loader = torch.utils.data.DataLoader(\n",
    "#    datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
    "#    batch_size=BATCH_SIZE, shuffle=True, **kwargs)               \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kmer_path = \"data\\kmers-gzip\\\\output.txt.gz\"\n",
    "\n",
    "kmer_all = pd.read_csv(kmer_path ,delim_whitespace=True, compression=\"gzip\", names = [\"kmer\", \"count\"], index_col = 0)\n",
    "\n",
    "#kmers = kmer_all.set_index(\"kmer\", drop=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kmer_culled = kmer_all.loc[kmer_all['count'] >= 700].copy()\n",
    "print(kmer_all.describe())\n",
    "\n",
    "print(kmer_culled.describe())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kmer_path = \"data\\kmers-gzip\\\\s314.txt.gz\"\n",
    "kmer_path2 = \"data\\kmers-gzip\\\\upec-261.txt.gz\"\n",
    "\n",
    "\n",
    "kmer_contig1 = pd.read_csv(kmer_path ,delim_whitespace=True, compression=\"gzip\", names = [\"kmer\", \"count\"], index_col = 0)\n",
    "kmer_contig2 = pd.read_csv(kmer_path2 ,delim_whitespace=True, compression=\"gzip\", names = [\"kmer\", \"count\"], index_col = 0)\n",
    "\n",
    "\n",
    "kmer_contig1.sort_values(by=\"kmer\", inplace=True)\n",
    "\n",
    "\n",
    "contig1_parsed = kmer_contig1[kmer_contig1.index.isin(kmer_culled.index)]\n",
    "contig2_parsed = kmer_contig2[kmer_contig2.index.isin(kmer_culled.index)]\n",
    "\n",
    "\n",
    "kmer_temp = kmer_culled.copy()\n",
    "kmer_temp['count'] = '0'\n",
    "kmer_temp.sort_values(by='kmer', inplace=True)\n",
    "\n",
    "print(contig1_parsed)\n",
    "print(kmer_temp.head(70))\n",
    "print(kmer_temp.loc[\"AAAAACTCTGCTTACCAGGCGCATTTCGCCC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kmer_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig1_merged = pd.merge(contig1_parsed, kmer_temp, how='right',on='kmer')\n",
    "contig2_merged = contig2_parsed.merge(kmer_temp, how='right',on='kmer')\n",
    "\n",
    "contig_noNull = contig1_merged[[ 'count_x']].fillna(value='0').copy()\n",
    "contig_noNull2 = contig2_merged[[ 'count_x']].fillna(value='0').copy()\n",
    "pd.isnull(contig_noNull)\n",
    "\n",
    "\n",
    "contig_noNull.sort_values(by=['kmer'], inplace=True)\n",
    "contig_noNull2.sort_values(by=['kmer'], inplace=True)\n",
    "\n",
    "#print(kmer_temp.describe())\n",
    "\n",
    "print(contig_noNull.head(10))\n",
    "print(contig_noNull2.head(10))\n",
    "#contig_clean = contig1_merged[['kmer', 'count_x']].copy()\n",
    "#contig_clean.head()\n",
    "#pd.isnull(contig_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "CULL_SIZE = 700\n",
    "\n",
    "class KmerDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dirname):\n",
    "        files = os.listdir(dirname)\n",
    "        max_kmer = 0\n",
    "        X, y = [],[]\n",
    "        kmer_all = pd.read_csv('data\\kmers-gzip\\\\output.txt.gz' ,delim_whitespace=True, compression=\"gzip\", names = [\"kmer\", \"count\"])\n",
    "        kmer_culled = kmer_all.loc[kmer_all['count'] >= CULL_SIZE]\n",
    "        kmer_temp = kmer_culled.copy()\n",
    "        kmer_temp['count'] = '0'\n",
    "        kmer_temp.sort_values(by=['kmer'], inplace=True)\n",
    "        self.template = kmer_temp\n",
    "        self.feature_dim = len(kmer_temp)\n",
    "        for line in files:\n",
    "            if(line != 'output.txt.gz'):\n",
    "\n",
    "                kmer_path = dirname + '\\\\' + line\n",
    "                kmer_df = pd.read_csv(kmer_path ,delim_whitespace=True, compression=\"gzip\", names = [\"kmer\", \"count\"])\n",
    "                contig_parsed = kmer_df[kmer_df.kmer.isin(self.template.kmer)]\n",
    "                contig_merged = contig_parsed.merge(self.template, how='right',on='kmer')\n",
    "\n",
    "                contig_final = contig_merged[['kmer', 'count_x']].fillna(value=0).copy()\n",
    "                contig_final.sort_values(by=['kmer'], inplace=True)\n",
    "                contig_vec = torch.tensor(contig_final['count_x'].values, dtype=torch.float)\n",
    "                X.append(contig_vec)\n",
    "                contig_max = torch.max(contig_vec)\n",
    "                if(contig_max > max_kmer): max_kmer = contig_max\n",
    "                \n",
    "        self.X = X\n",
    "        self.max_kmer = max_kmer\n",
    "    \n",
    "    def preprocess(self, contig):\n",
    "        \n",
    "        norm_vec = torch.div(contig, self.max_kmer)\n",
    "\n",
    "        #print(contig_final.head(10))\n",
    "        \n",
    "        #print(np.isnan(contig_vec))\n",
    "        \n",
    "        return norm_vec\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.preprocess(self.X[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize dataset\n",
    "dataset = KmerDataset('data\\kmers-gzip')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8763\n"
     ]
    }
   ],
   "source": [
    "#Separate into train/val\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(VALIDATION_SPLIT * dataset_size))\n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "#initialize data loaders\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, \n",
    "                                           sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                                                sampler=valid_sampler)\n",
    "FEATURE_SIZE = dataset.feature_dim\n",
    "print(FEATURE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Variable is deprecated update at some point\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(FEATURE_SIZE, ENCODER_DIMS)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc21 = nn.Linear(ENCODER_DIMS, ZDIMS)\n",
    "        self.fc22 = nn.Linear(ENCODER_DIMS, ZDIMS)\n",
    "        \n",
    "        \n",
    "        self.fc3 = nn.Linear(ZDIMS, DECODER_DIMS)\n",
    "        \n",
    "        self.fc4 = nn.Linear(DECODER_DIMS, FEATURE_SIZE)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    \n",
    "    #if in training creates random vector based on mean and stddev\n",
    "    #if in otherwise returns constant mean for backprop\n",
    "    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n",
    "        \n",
    "        if self.training:\n",
    "            \n",
    "            std = logvar.mul(.5).exp_()\n",
    "            \n",
    "            eps = std.data.new(std.size()).normal_()\n",
    "            \n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def encode(self, x: Tensor) -> (Tensor, Tensor):\n",
    "        \n",
    "        h1 = self.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "    \n",
    "    def decode(self, z: Tensor) -> Tensor:\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        return self.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x: Tensor) -> (Tensor, Tensor, Tensor):\n",
    "        #feed forward for the network\n",
    "        \n",
    "        #encodes data into mean(mu) and logvarience(logvar, ln(sigma^2))\n",
    "        mu, logvar = self.encode(x.view(-1, FEATURE_SIZE))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = VAE().to(device)\n",
    "\n",
    "\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, FEATURE_SIZE))\n",
    "    \n",
    "    \n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    KLD /= BATCH_SIZE * FEATURE_SIZE\n",
    "    \n",
    "    return BCE + KLD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(epoch):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for i in enumerate(train_loader):\n",
    "        data = i[1]\n",
    "        batch_idx = i[0]\n",
    "        data = data.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        \n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len (train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader),\n",
    "            loss.data.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "        epoch, train_loss / len(train_loader.dataset)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i in enumerate(test_loader):\n",
    "            data = i[1]\n",
    "            if CUDA:\n",
    "                data = data.cuda()\n",
    "        \n",
    "        \n",
    "                recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).data.item()\n",
    "            torch.cuda.empty_cache\n",
    "        \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/347 (0%)]\tLoss: 0.029000\n",
      "Train Epoch: 1 [10/347 (4%)]\tLoss: 0.064315\n",
      "Train Epoch: 1 [20/347 (7%)]\tLoss: 0.025125\n",
      "Train Epoch: 1 [30/347 (11%)]\tLoss: 0.085514\n",
      "Train Epoch: 1 [40/347 (14%)]\tLoss: 0.087538\n",
      "Train Epoch: 1 [50/347 (18%)]\tLoss: 0.069661\n",
      "Train Epoch: 1 [60/347 (22%)]\tLoss: 0.033249\n",
      "Train Epoch: 1 [70/347 (25%)]\tLoss: 0.052722\n",
      "Train Epoch: 1 [80/347 (29%)]\tLoss: 0.067163\n",
      "Train Epoch: 1 [90/347 (32%)]\tLoss: 0.119969\n",
      "Train Epoch: 1 [100/347 (36%)]\tLoss: 0.060958\n",
      "Train Epoch: 1 [110/347 (40%)]\tLoss: 0.023962\n",
      "Train Epoch: 1 [120/347 (43%)]\tLoss: 0.022500\n",
      "Train Epoch: 1 [130/347 (47%)]\tLoss: 0.032701\n",
      "Train Epoch: 1 [140/347 (50%)]\tLoss: 0.033330\n",
      "Train Epoch: 1 [150/347 (54%)]\tLoss: 0.056419\n",
      "Train Epoch: 1 [160/347 (58%)]\tLoss: 0.037024\n",
      "Train Epoch: 1 [170/347 (61%)]\tLoss: 0.038130\n",
      "Train Epoch: 1 [180/347 (65%)]\tLoss: 0.123158\n",
      "Train Epoch: 1 [190/347 (68%)]\tLoss: 0.022922\n",
      "Train Epoch: 1 [200/347 (72%)]\tLoss: 0.028078\n",
      "Train Epoch: 1 [210/347 (76%)]\tLoss: 0.043082\n",
      "Train Epoch: 1 [220/347 (79%)]\tLoss: 0.026633\n",
      "Train Epoch: 1 [230/347 (83%)]\tLoss: 0.049058\n",
      "Train Epoch: 1 [240/347 (86%)]\tLoss: 0.026947\n",
      "Train Epoch: 1 [250/347 (90%)]\tLoss: 0.062046\n",
      "Train Epoch: 1 [260/347 (94%)]\tLoss: 0.105464\n",
      "Train Epoch: 1 [270/347 (97%)]\tLoss: 0.078789\n",
      "====> Epoch: 1 Average loss: 0.0407\n",
      "====> Test set loss: 0.0134\n",
      "Train Epoch: 2 [0/347 (0%)]\tLoss: 0.029188\n",
      "Train Epoch: 2 [10/347 (4%)]\tLoss: 0.034203\n",
      "Train Epoch: 2 [20/347 (7%)]\tLoss: 0.128470\n",
      "Train Epoch: 2 [30/347 (11%)]\tLoss: 0.067966\n",
      "Train Epoch: 2 [40/347 (14%)]\tLoss: 0.060703\n",
      "Train Epoch: 2 [50/347 (18%)]\tLoss: 0.026399\n",
      "Train Epoch: 2 [60/347 (22%)]\tLoss: 0.079999\n",
      "Train Epoch: 2 [70/347 (25%)]\tLoss: 0.028029\n",
      "Train Epoch: 2 [80/347 (29%)]\tLoss: 0.068022\n",
      "Train Epoch: 2 [90/347 (32%)]\tLoss: 0.051676\n",
      "Train Epoch: 2 [100/347 (36%)]\tLoss: 0.068638\n",
      "Train Epoch: 2 [110/347 (40%)]\tLoss: 0.053571\n",
      "Train Epoch: 2 [120/347 (43%)]\tLoss: 0.077407\n",
      "Train Epoch: 2 [130/347 (47%)]\tLoss: 0.036465\n",
      "Train Epoch: 2 [140/347 (50%)]\tLoss: 0.027430\n",
      "Train Epoch: 2 [150/347 (54%)]\tLoss: 0.057060\n",
      "Train Epoch: 2 [160/347 (58%)]\tLoss: 0.028374\n",
      "Train Epoch: 2 [170/347 (61%)]\tLoss: 0.064495\n",
      "Train Epoch: 2 [180/347 (65%)]\tLoss: 0.080307\n",
      "Train Epoch: 2 [190/347 (68%)]\tLoss: 0.067676\n",
      "Train Epoch: 2 [200/347 (72%)]\tLoss: 0.082753\n",
      "Train Epoch: 2 [210/347 (76%)]\tLoss: 0.026852\n",
      "Train Epoch: 2 [220/347 (79%)]\tLoss: 0.026993\n",
      "Train Epoch: 2 [230/347 (83%)]\tLoss: 0.023932\n",
      "Train Epoch: 2 [240/347 (86%)]\tLoss: 0.041356\n",
      "Train Epoch: 2 [250/347 (90%)]\tLoss: 0.076367\n",
      "Train Epoch: 2 [260/347 (94%)]\tLoss: 0.071596\n",
      "Train Epoch: 2 [270/347 (97%)]\tLoss: 0.037233\n",
      "====> Epoch: 2 Average loss: 0.0401\n",
      "====> Test set loss: 0.0112\n",
      "Train Epoch: 3 [0/347 (0%)]\tLoss: 0.034970\n",
      "Train Epoch: 3 [10/347 (4%)]\tLoss: 0.061927\n",
      "Train Epoch: 3 [20/347 (7%)]\tLoss: 0.027154\n",
      "Train Epoch: 3 [30/347 (11%)]\tLoss: 0.029675\n",
      "Train Epoch: 3 [40/347 (14%)]\tLoss: 0.084887\n",
      "Train Epoch: 3 [50/347 (18%)]\tLoss: 0.066663\n",
      "Train Epoch: 3 [60/347 (22%)]\tLoss: 0.020152\n",
      "Train Epoch: 3 [70/347 (25%)]\tLoss: 0.036713\n",
      "Train Epoch: 3 [80/347 (29%)]\tLoss: 0.059923\n",
      "Train Epoch: 3 [90/347 (32%)]\tLoss: 0.044197\n",
      "Train Epoch: 3 [100/347 (36%)]\tLoss: 0.078205\n",
      "Train Epoch: 3 [110/347 (40%)]\tLoss: 0.033854\n",
      "Train Epoch: 3 [120/347 (43%)]\tLoss: 0.055748\n",
      "Train Epoch: 3 [130/347 (47%)]\tLoss: 0.054105\n",
      "Train Epoch: 3 [140/347 (50%)]\tLoss: 0.044469\n",
      "Train Epoch: 3 [150/347 (54%)]\tLoss: 0.033920\n",
      "Train Epoch: 3 [160/347 (58%)]\tLoss: 0.072563\n",
      "Train Epoch: 3 [170/347 (61%)]\tLoss: 0.033785\n",
      "Train Epoch: 3 [180/347 (65%)]\tLoss: 0.085725\n",
      "Train Epoch: 3 [190/347 (68%)]\tLoss: 0.023973\n",
      "Train Epoch: 3 [200/347 (72%)]\tLoss: 0.036369\n",
      "Train Epoch: 3 [210/347 (76%)]\tLoss: 0.061358\n",
      "Train Epoch: 3 [220/347 (79%)]\tLoss: 0.045060\n",
      "Train Epoch: 3 [230/347 (83%)]\tLoss: 0.050883\n",
      "Train Epoch: 3 [240/347 (86%)]\tLoss: 0.080017\n",
      "Train Epoch: 3 [250/347 (90%)]\tLoss: 0.022849\n",
      "Train Epoch: 3 [260/347 (94%)]\tLoss: 0.085329\n",
      "Train Epoch: 3 [270/347 (97%)]\tLoss: 0.036287\n",
      "====> Epoch: 3 Average loss: 0.0398\n",
      "====> Test set loss: 0.0121\n",
      "Train Epoch: 4 [0/347 (0%)]\tLoss: 0.039292\n",
      "Train Epoch: 4 [10/347 (4%)]\tLoss: 0.029125\n",
      "Train Epoch: 4 [20/347 (7%)]\tLoss: 0.038234\n",
      "Train Epoch: 4 [30/347 (11%)]\tLoss: 0.039465\n",
      "Train Epoch: 4 [40/347 (14%)]\tLoss: 0.035207\n",
      "Train Epoch: 4 [50/347 (18%)]\tLoss: 0.027642\n",
      "Train Epoch: 4 [60/347 (22%)]\tLoss: 0.030071\n",
      "Train Epoch: 4 [70/347 (25%)]\tLoss: 0.027708\n",
      "Train Epoch: 4 [80/347 (29%)]\tLoss: 0.066502\n",
      "Train Epoch: 4 [90/347 (32%)]\tLoss: 0.023288\n",
      "Train Epoch: 4 [100/347 (36%)]\tLoss: 0.034092\n",
      "Train Epoch: 4 [110/347 (40%)]\tLoss: 0.033014\n",
      "Train Epoch: 4 [120/347 (43%)]\tLoss: 0.034905\n",
      "Train Epoch: 4 [130/347 (47%)]\tLoss: 0.096448\n",
      "Train Epoch: 4 [140/347 (50%)]\tLoss: 0.043678\n",
      "Train Epoch: 4 [150/347 (54%)]\tLoss: 0.050912\n",
      "Train Epoch: 4 [160/347 (58%)]\tLoss: 0.031925\n",
      "Train Epoch: 4 [170/347 (61%)]\tLoss: 0.046259\n",
      "Train Epoch: 4 [180/347 (65%)]\tLoss: 0.038004\n",
      "Train Epoch: 4 [190/347 (68%)]\tLoss: 0.065860\n",
      "Train Epoch: 4 [200/347 (72%)]\tLoss: 0.040912\n",
      "Train Epoch: 4 [210/347 (76%)]\tLoss: 0.070848\n",
      "Train Epoch: 4 [220/347 (79%)]\tLoss: 0.089307\n",
      "Train Epoch: 4 [230/347 (83%)]\tLoss: 0.041777\n",
      "Train Epoch: 4 [240/347 (86%)]\tLoss: 0.034965\n",
      "Train Epoch: 4 [250/347 (90%)]\tLoss: 0.048827\n",
      "Train Epoch: 4 [260/347 (94%)]\tLoss: 0.060714\n",
      "Train Epoch: 4 [270/347 (97%)]\tLoss: 0.033195\n",
      "====> Epoch: 4 Average loss: 0.0398\n",
      "====> Test set loss: 0.0120\n",
      "Train Epoch: 5 [0/347 (0%)]\tLoss: 0.027227\n",
      "Train Epoch: 5 [10/347 (4%)]\tLoss: 0.091141\n",
      "Train Epoch: 5 [20/347 (7%)]\tLoss: 0.032336\n",
      "Train Epoch: 5 [30/347 (11%)]\tLoss: 0.038737\n",
      "Train Epoch: 5 [40/347 (14%)]\tLoss: 0.026296\n",
      "Train Epoch: 5 [50/347 (18%)]\tLoss: 0.032419\n",
      "Train Epoch: 5 [60/347 (22%)]\tLoss: 0.059232\n",
      "Train Epoch: 5 [70/347 (25%)]\tLoss: 0.028156\n",
      "Train Epoch: 5 [80/347 (29%)]\tLoss: 0.046381\n",
      "Train Epoch: 5 [90/347 (32%)]\tLoss: 0.031116\n",
      "Train Epoch: 5 [100/347 (36%)]\tLoss: 0.033584\n",
      "Train Epoch: 5 [110/347 (40%)]\tLoss: 0.035194\n",
      "Train Epoch: 5 [120/347 (43%)]\tLoss: 0.044429\n",
      "Train Epoch: 5 [130/347 (47%)]\tLoss: 0.042950\n",
      "Train Epoch: 5 [140/347 (50%)]\tLoss: 0.122044\n",
      "Train Epoch: 5 [150/347 (54%)]\tLoss: 0.033759\n",
      "Train Epoch: 5 [160/347 (58%)]\tLoss: 0.028570\n",
      "Train Epoch: 5 [170/347 (61%)]\tLoss: 0.034870\n",
      "Train Epoch: 5 [180/347 (65%)]\tLoss: 0.060509\n",
      "Train Epoch: 5 [190/347 (68%)]\tLoss: 0.026944\n",
      "Train Epoch: 5 [200/347 (72%)]\tLoss: 0.067102\n",
      "Train Epoch: 5 [210/347 (76%)]\tLoss: 0.077028\n",
      "Train Epoch: 5 [220/347 (79%)]\tLoss: 0.107963\n",
      "Train Epoch: 5 [230/347 (83%)]\tLoss: 0.035152\n",
      "Train Epoch: 5 [240/347 (86%)]\tLoss: 0.021181\n",
      "Train Epoch: 5 [250/347 (90%)]\tLoss: 0.061240\n",
      "Train Epoch: 5 [260/347 (94%)]\tLoss: 0.053348\n",
      "Train Epoch: 5 [270/347 (97%)]\tLoss: 0.074546\n",
      "====> Epoch: 5 Average loss: 0.0396\n",
      "====> Test set loss: 0.0108\n",
      "Train Epoch: 6 [0/347 (0%)]\tLoss: 0.042028\n",
      "Train Epoch: 6 [10/347 (4%)]\tLoss: 0.059160\n",
      "Train Epoch: 6 [20/347 (7%)]\tLoss: 0.083946\n",
      "Train Epoch: 6 [30/347 (11%)]\tLoss: 0.034575\n",
      "Train Epoch: 6 [40/347 (14%)]\tLoss: 0.106443\n",
      "Train Epoch: 6 [50/347 (18%)]\tLoss: 0.110115\n",
      "Train Epoch: 6 [60/347 (22%)]\tLoss: 0.030736\n",
      "Train Epoch: 6 [70/347 (25%)]\tLoss: 0.081424\n",
      "Train Epoch: 6 [80/347 (29%)]\tLoss: 0.029515\n",
      "Train Epoch: 6 [90/347 (32%)]\tLoss: 0.029948\n",
      "Train Epoch: 6 [100/347 (36%)]\tLoss: 0.102931\n",
      "Train Epoch: 6 [110/347 (40%)]\tLoss: 0.054687\n",
      "Train Epoch: 6 [120/347 (43%)]\tLoss: 0.095042\n",
      "Train Epoch: 6 [130/347 (47%)]\tLoss: 0.110622\n",
      "Train Epoch: 6 [140/347 (50%)]\tLoss: 0.095992\n",
      "Train Epoch: 6 [150/347 (54%)]\tLoss: 0.037226\n",
      "Train Epoch: 6 [160/347 (58%)]\tLoss: 0.053831\n",
      "Train Epoch: 6 [170/347 (61%)]\tLoss: 0.033635\n",
      "Train Epoch: 6 [180/347 (65%)]\tLoss: 0.019298\n",
      "Train Epoch: 6 [190/347 (68%)]\tLoss: 0.060423\n",
      "Train Epoch: 6 [200/347 (72%)]\tLoss: 0.030556\n",
      "Train Epoch: 6 [210/347 (76%)]\tLoss: 0.029268\n",
      "Train Epoch: 6 [220/347 (79%)]\tLoss: 0.034227\n",
      "Train Epoch: 6 [230/347 (83%)]\tLoss: 0.090866\n",
      "Train Epoch: 6 [240/347 (86%)]\tLoss: 0.041817\n",
      "Train Epoch: 6 [250/347 (90%)]\tLoss: 0.031349\n",
      "Train Epoch: 6 [260/347 (94%)]\tLoss: 0.028101\n",
      "Train Epoch: 6 [270/347 (97%)]\tLoss: 0.056018\n",
      "====> Epoch: 6 Average loss: 0.0396\n",
      "====> Test set loss: 0.0114\n",
      "Train Epoch: 7 [0/347 (0%)]\tLoss: 0.055909\n",
      "Train Epoch: 7 [10/347 (4%)]\tLoss: 0.035165\n",
      "Train Epoch: 7 [20/347 (7%)]\tLoss: 0.058306\n",
      "Train Epoch: 7 [30/347 (11%)]\tLoss: 0.056718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [40/347 (14%)]\tLoss: 0.022167\n",
      "Train Epoch: 7 [50/347 (18%)]\tLoss: 0.042624\n",
      "Train Epoch: 7 [60/347 (22%)]\tLoss: 0.101970\n",
      "Train Epoch: 7 [70/347 (25%)]\tLoss: 0.032753\n",
      "Train Epoch: 7 [80/347 (29%)]\tLoss: 0.054882\n",
      "Train Epoch: 7 [90/347 (32%)]\tLoss: 0.036702\n",
      "Train Epoch: 7 [100/347 (36%)]\tLoss: 0.080164\n",
      "Train Epoch: 7 [110/347 (40%)]\tLoss: 0.050898\n",
      "Train Epoch: 7 [120/347 (43%)]\tLoss: 0.033298\n",
      "Train Epoch: 7 [130/347 (47%)]\tLoss: 0.031640\n",
      "Train Epoch: 7 [140/347 (50%)]\tLoss: 0.055590\n",
      "Train Epoch: 7 [150/347 (54%)]\tLoss: 0.024361\n",
      "Train Epoch: 7 [160/347 (58%)]\tLoss: 0.035623\n",
      "Train Epoch: 7 [170/347 (61%)]\tLoss: 0.033730\n",
      "Train Epoch: 7 [180/347 (65%)]\tLoss: 0.024511\n",
      "Train Epoch: 7 [190/347 (68%)]\tLoss: 0.050774\n",
      "Train Epoch: 7 [200/347 (72%)]\tLoss: 0.119904\n",
      "Train Epoch: 7 [210/347 (76%)]\tLoss: 0.021593\n",
      "Train Epoch: 7 [220/347 (79%)]\tLoss: 0.028144\n",
      "Train Epoch: 7 [230/347 (83%)]\tLoss: 0.028783\n",
      "Train Epoch: 7 [240/347 (86%)]\tLoss: 0.048872\n",
      "Train Epoch: 7 [250/347 (90%)]\tLoss: 0.016447\n",
      "Train Epoch: 7 [260/347 (94%)]\tLoss: 0.044828\n",
      "Train Epoch: 7 [270/347 (97%)]\tLoss: 0.088553\n",
      "====> Epoch: 7 Average loss: 0.0403\n",
      "====> Test set loss: 0.0111\n",
      "Train Epoch: 8 [0/347 (0%)]\tLoss: 0.032093\n",
      "Train Epoch: 8 [10/347 (4%)]\tLoss: 0.089762\n",
      "Train Epoch: 8 [20/347 (7%)]\tLoss: 0.067201\n",
      "Train Epoch: 8 [30/347 (11%)]\tLoss: 0.027567\n",
      "Train Epoch: 8 [40/347 (14%)]\tLoss: 0.018058\n",
      "Train Epoch: 8 [50/347 (18%)]\tLoss: 0.031179\n",
      "Train Epoch: 8 [60/347 (22%)]\tLoss: 0.032148\n",
      "Train Epoch: 8 [70/347 (25%)]\tLoss: 0.081526\n",
      "Train Epoch: 8 [80/347 (29%)]\tLoss: 0.028555\n",
      "Train Epoch: 8 [90/347 (32%)]\tLoss: 0.032048\n",
      "Train Epoch: 8 [100/347 (36%)]\tLoss: 0.069574\n",
      "Train Epoch: 8 [110/347 (40%)]\tLoss: 0.094489\n",
      "Train Epoch: 8 [120/347 (43%)]\tLoss: 0.032873\n",
      "Train Epoch: 8 [130/347 (47%)]\tLoss: 0.034319\n",
      "Train Epoch: 8 [140/347 (50%)]\tLoss: 0.036126\n",
      "Train Epoch: 8 [150/347 (54%)]\tLoss: 0.077422\n",
      "Train Epoch: 8 [160/347 (58%)]\tLoss: 0.105934\n",
      "Train Epoch: 8 [170/347 (61%)]\tLoss: 0.070852\n",
      "Train Epoch: 8 [180/347 (65%)]\tLoss: 0.031990\n",
      "Train Epoch: 8 [190/347 (68%)]\tLoss: 0.057435\n",
      "Train Epoch: 8 [200/347 (72%)]\tLoss: 0.035348\n",
      "Train Epoch: 8 [210/347 (76%)]\tLoss: 0.060400\n",
      "Train Epoch: 8 [220/347 (79%)]\tLoss: 0.096330\n",
      "Train Epoch: 8 [230/347 (83%)]\tLoss: 0.069585\n",
      "Train Epoch: 8 [240/347 (86%)]\tLoss: 0.067853\n",
      "Train Epoch: 8 [250/347 (90%)]\tLoss: 0.073778\n",
      "Train Epoch: 8 [260/347 (94%)]\tLoss: 0.091359\n",
      "Train Epoch: 8 [270/347 (97%)]\tLoss: 0.029199\n",
      "====> Epoch: 8 Average loss: 0.0394\n",
      "====> Test set loss: 0.0111\n",
      "Train Epoch: 9 [0/347 (0%)]\tLoss: 0.051987\n",
      "Train Epoch: 9 [10/347 (4%)]\tLoss: 0.030974\n",
      "Train Epoch: 9 [20/347 (7%)]\tLoss: 0.026807\n",
      "Train Epoch: 9 [30/347 (11%)]\tLoss: 0.027218\n",
      "Train Epoch: 9 [40/347 (14%)]\tLoss: 0.101504\n",
      "Train Epoch: 9 [50/347 (18%)]\tLoss: 0.064023\n",
      "Train Epoch: 9 [60/347 (22%)]\tLoss: 0.037702\n",
      "Train Epoch: 9 [70/347 (25%)]\tLoss: 0.031853\n",
      "Train Epoch: 9 [80/347 (29%)]\tLoss: 0.044469\n",
      "Train Epoch: 9 [90/347 (32%)]\tLoss: 0.037073\n",
      "Train Epoch: 9 [100/347 (36%)]\tLoss: 0.063134\n",
      "Train Epoch: 9 [110/347 (40%)]\tLoss: 0.048121\n",
      "Train Epoch: 9 [120/347 (43%)]\tLoss: 0.103218\n",
      "Train Epoch: 9 [130/347 (47%)]\tLoss: 0.056597\n",
      "Train Epoch: 9 [140/347 (50%)]\tLoss: 0.029921\n",
      "Train Epoch: 9 [150/347 (54%)]\tLoss: 0.022881\n",
      "Train Epoch: 9 [160/347 (58%)]\tLoss: 0.035087\n",
      "Train Epoch: 9 [170/347 (61%)]\tLoss: 0.093204\n",
      "Train Epoch: 9 [180/347 (65%)]\tLoss: 0.070167\n",
      "Train Epoch: 9 [190/347 (68%)]\tLoss: 0.027426\n",
      "Train Epoch: 9 [200/347 (72%)]\tLoss: 0.033026\n",
      "Train Epoch: 9 [210/347 (76%)]\tLoss: 0.028919\n",
      "Train Epoch: 9 [220/347 (79%)]\tLoss: 0.083840\n",
      "Train Epoch: 9 [230/347 (83%)]\tLoss: 0.026075\n",
      "Train Epoch: 9 [240/347 (86%)]\tLoss: 0.027637\n",
      "Train Epoch: 9 [250/347 (90%)]\tLoss: 0.037424\n",
      "Train Epoch: 9 [260/347 (94%)]\tLoss: 0.064744\n",
      "Train Epoch: 9 [270/347 (97%)]\tLoss: 0.040177\n",
      "====> Epoch: 9 Average loss: 0.0393\n",
      "====> Test set loss: 0.0109\n",
      "Train Epoch: 10 [0/347 (0%)]\tLoss: 0.027062\n",
      "Train Epoch: 10 [10/347 (4%)]\tLoss: 0.027856\n",
      "Train Epoch: 10 [20/347 (7%)]\tLoss: 0.027758\n",
      "Train Epoch: 10 [30/347 (11%)]\tLoss: 0.070110\n",
      "Train Epoch: 10 [40/347 (14%)]\tLoss: 0.034981\n",
      "Train Epoch: 10 [50/347 (18%)]\tLoss: 0.035055\n",
      "Train Epoch: 10 [60/347 (22%)]\tLoss: 0.061752\n",
      "Train Epoch: 10 [70/347 (25%)]\tLoss: 0.026792\n",
      "Train Epoch: 10 [80/347 (29%)]\tLoss: 0.049177\n",
      "Train Epoch: 10 [90/347 (32%)]\tLoss: 0.031878\n",
      "Train Epoch: 10 [100/347 (36%)]\tLoss: 0.035003\n",
      "Train Epoch: 10 [110/347 (40%)]\tLoss: 0.039199\n",
      "Train Epoch: 10 [120/347 (43%)]\tLoss: 0.029468\n",
      "Train Epoch: 10 [130/347 (47%)]\tLoss: 0.032431\n",
      "Train Epoch: 10 [140/347 (50%)]\tLoss: 0.025238\n",
      "Train Epoch: 10 [150/347 (54%)]\tLoss: 0.027158\n",
      "Train Epoch: 10 [160/347 (58%)]\tLoss: 0.082835\n",
      "Train Epoch: 10 [170/347 (61%)]\tLoss: 0.026928\n",
      "Train Epoch: 10 [180/347 (65%)]\tLoss: 0.096241\n",
      "Train Epoch: 10 [190/347 (68%)]\tLoss: 0.028476\n",
      "Train Epoch: 10 [200/347 (72%)]\tLoss: 0.030998\n",
      "Train Epoch: 10 [210/347 (76%)]\tLoss: 0.035578\n",
      "Train Epoch: 10 [220/347 (79%)]\tLoss: 0.086998\n",
      "Train Epoch: 10 [230/347 (83%)]\tLoss: 0.025310\n",
      "Train Epoch: 10 [240/347 (86%)]\tLoss: 0.053443\n",
      "Train Epoch: 10 [250/347 (90%)]\tLoss: 0.023048\n",
      "Train Epoch: 10 [260/347 (94%)]\tLoss: 0.050837\n",
      "Train Epoch: 10 [270/347 (97%)]\tLoss: 0.028860\n",
      "====> Epoch: 10 Average loss: 0.0394\n",
      "====> Test set loss: 0.0109\n",
      "Train Epoch: 11 [0/347 (0%)]\tLoss: 0.035081\n",
      "Train Epoch: 11 [10/347 (4%)]\tLoss: 0.028784\n",
      "Train Epoch: 11 [20/347 (7%)]\tLoss: 0.097981\n",
      "Train Epoch: 11 [30/347 (11%)]\tLoss: 0.027332\n",
      "Train Epoch: 11 [40/347 (14%)]\tLoss: 0.026761\n",
      "Train Epoch: 11 [50/347 (18%)]\tLoss: 0.036565\n",
      "Train Epoch: 11 [60/347 (22%)]\tLoss: 0.052150\n",
      "Train Epoch: 11 [70/347 (25%)]\tLoss: 0.084720\n",
      "Train Epoch: 11 [80/347 (29%)]\tLoss: 0.040483\n",
      "Train Epoch: 11 [90/347 (32%)]\tLoss: 0.085022\n",
      "Train Epoch: 11 [100/347 (36%)]\tLoss: 0.025331\n",
      "Train Epoch: 11 [110/347 (40%)]\tLoss: 0.105200\n",
      "Train Epoch: 11 [120/347 (43%)]\tLoss: 0.062725\n",
      "Train Epoch: 11 [130/347 (47%)]\tLoss: 0.036361\n",
      "Train Epoch: 11 [140/347 (50%)]\tLoss: 0.028336\n",
      "Train Epoch: 11 [150/347 (54%)]\tLoss: 0.068496\n",
      "Train Epoch: 11 [160/347 (58%)]\tLoss: 0.031843\n",
      "Train Epoch: 11 [170/347 (61%)]\tLoss: 0.051792\n",
      "Train Epoch: 11 [180/347 (65%)]\tLoss: 0.049988\n",
      "Train Epoch: 11 [190/347 (68%)]\tLoss: 0.029603\n",
      "Train Epoch: 11 [200/347 (72%)]\tLoss: 0.061564\n",
      "Train Epoch: 11 [210/347 (76%)]\tLoss: 0.057139\n",
      "Train Epoch: 11 [220/347 (79%)]\tLoss: 0.086660\n",
      "Train Epoch: 11 [230/347 (83%)]\tLoss: 0.079383\n",
      "Train Epoch: 11 [240/347 (86%)]\tLoss: 0.033518\n",
      "Train Epoch: 11 [250/347 (90%)]\tLoss: 0.057122\n",
      "Train Epoch: 11 [260/347 (94%)]\tLoss: 0.050671\n",
      "Train Epoch: 11 [270/347 (97%)]\tLoss: 0.070181\n",
      "====> Epoch: 11 Average loss: 0.0393\n",
      "====> Test set loss: 0.0102\n",
      "Train Epoch: 12 [0/347 (0%)]\tLoss: 0.027503\n",
      "Train Epoch: 12 [10/347 (4%)]\tLoss: 0.067032\n",
      "Train Epoch: 12 [20/347 (7%)]\tLoss: 0.079139\n",
      "Train Epoch: 12 [30/347 (11%)]\tLoss: 0.029885\n",
      "Train Epoch: 12 [40/347 (14%)]\tLoss: 0.071341\n",
      "Train Epoch: 12 [50/347 (18%)]\tLoss: 0.039594\n",
      "Train Epoch: 12 [60/347 (22%)]\tLoss: 0.022615\n",
      "Train Epoch: 12 [70/347 (25%)]\tLoss: 0.054853\n",
      "Train Epoch: 12 [80/347 (29%)]\tLoss: 0.039678\n",
      "Train Epoch: 12 [90/347 (32%)]\tLoss: 0.034961\n",
      "Train Epoch: 12 [100/347 (36%)]\tLoss: 0.032031\n",
      "Train Epoch: 12 [110/347 (40%)]\tLoss: 0.072099\n",
      "Train Epoch: 12 [120/347 (43%)]\tLoss: 0.040728\n",
      "Train Epoch: 12 [130/347 (47%)]\tLoss: 0.026283\n",
      "Train Epoch: 12 [140/347 (50%)]\tLoss: 0.047760\n",
      "Train Epoch: 12 [150/347 (54%)]\tLoss: 0.089434\n",
      "Train Epoch: 12 [160/347 (58%)]\tLoss: 0.028237\n",
      "Train Epoch: 12 [170/347 (61%)]\tLoss: 0.033367\n",
      "Train Epoch: 12 [180/347 (65%)]\tLoss: 0.098405\n",
      "Train Epoch: 12 [190/347 (68%)]\tLoss: 0.038648\n",
      "Train Epoch: 12 [200/347 (72%)]\tLoss: 0.064565\n",
      "Train Epoch: 12 [210/347 (76%)]\tLoss: 0.063022\n",
      "Train Epoch: 12 [220/347 (79%)]\tLoss: 0.025729\n",
      "Train Epoch: 12 [230/347 (83%)]\tLoss: 0.028845\n",
      "Train Epoch: 12 [240/347 (86%)]\tLoss: 0.026953\n",
      "Train Epoch: 12 [250/347 (90%)]\tLoss: 0.031520\n",
      "Train Epoch: 12 [260/347 (94%)]\tLoss: 0.070738\n",
      "Train Epoch: 12 [270/347 (97%)]\tLoss: 0.103380\n",
      "====> Epoch: 12 Average loss: 0.0391\n",
      "====> Test set loss: 0.0109\n",
      "Train Epoch: 13 [0/347 (0%)]\tLoss: 0.088810\n",
      "Train Epoch: 13 [10/347 (4%)]\tLoss: 0.054660\n",
      "Train Epoch: 13 [20/347 (7%)]\tLoss: 0.105289\n",
      "Train Epoch: 13 [30/347 (11%)]\tLoss: 0.076495\n",
      "Train Epoch: 13 [40/347 (14%)]\tLoss: 0.037237\n",
      "Train Epoch: 13 [50/347 (18%)]\tLoss: 0.027446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [60/347 (22%)]\tLoss: 0.027838\n",
      "Train Epoch: 13 [70/347 (25%)]\tLoss: 0.034875\n",
      "Train Epoch: 13 [80/347 (29%)]\tLoss: 0.026957\n",
      "Train Epoch: 13 [90/347 (32%)]\tLoss: 0.064213\n",
      "Train Epoch: 13 [100/347 (36%)]\tLoss: 0.047201\n",
      "Train Epoch: 13 [110/347 (40%)]\tLoss: 0.041801\n",
      "Train Epoch: 13 [120/347 (43%)]\tLoss: 0.076802\n",
      "Train Epoch: 13 [130/347 (47%)]\tLoss: 0.040739\n",
      "Train Epoch: 13 [140/347 (50%)]\tLoss: 0.085755\n",
      "Train Epoch: 13 [150/347 (54%)]\tLoss: 0.038375\n",
      "Train Epoch: 13 [160/347 (58%)]\tLoss: 0.023113\n",
      "Train Epoch: 13 [170/347 (61%)]\tLoss: 0.045282\n",
      "Train Epoch: 13 [180/347 (65%)]\tLoss: 0.039898\n",
      "Train Epoch: 13 [190/347 (68%)]\tLoss: 0.060926\n",
      "Train Epoch: 13 [200/347 (72%)]\tLoss: 0.107674\n",
      "Train Epoch: 13 [210/347 (76%)]\tLoss: 0.047694\n",
      "Train Epoch: 13 [220/347 (79%)]\tLoss: 0.075841\n",
      "Train Epoch: 13 [230/347 (83%)]\tLoss: 0.066412\n",
      "Train Epoch: 13 [240/347 (86%)]\tLoss: 0.075773\n",
      "Train Epoch: 13 [250/347 (90%)]\tLoss: 0.033429\n",
      "Train Epoch: 13 [260/347 (94%)]\tLoss: 0.066651\n",
      "Train Epoch: 13 [270/347 (97%)]\tLoss: 0.035903\n",
      "====> Epoch: 13 Average loss: 0.0395\n",
      "====> Test set loss: 0.0105\n",
      "Train Epoch: 14 [0/347 (0%)]\tLoss: 0.024088\n",
      "Train Epoch: 14 [10/347 (4%)]\tLoss: 0.031309\n",
      "Train Epoch: 14 [20/347 (7%)]\tLoss: 0.027974\n",
      "Train Epoch: 14 [30/347 (11%)]\tLoss: 0.063332\n",
      "Train Epoch: 14 [40/347 (14%)]\tLoss: 0.026726\n",
      "Train Epoch: 14 [50/347 (18%)]\tLoss: 0.036675\n",
      "Train Epoch: 14 [60/347 (22%)]\tLoss: 0.025579\n",
      "Train Epoch: 14 [70/347 (25%)]\tLoss: 0.032449\n",
      "Train Epoch: 14 [80/347 (29%)]\tLoss: 0.045367\n",
      "Train Epoch: 14 [90/347 (32%)]\tLoss: 0.025776\n",
      "Train Epoch: 14 [100/347 (36%)]\tLoss: 0.053464\n",
      "Train Epoch: 14 [110/347 (40%)]\tLoss: 0.026132\n",
      "Train Epoch: 14 [120/347 (43%)]\tLoss: 0.058390\n",
      "Train Epoch: 14 [130/347 (47%)]\tLoss: 0.022594\n",
      "Train Epoch: 14 [140/347 (50%)]\tLoss: 0.039679\n",
      "Train Epoch: 14 [150/347 (54%)]\tLoss: 0.026233\n",
      "Train Epoch: 14 [160/347 (58%)]\tLoss: 0.060071\n",
      "Train Epoch: 14 [170/347 (61%)]\tLoss: 0.021896\n",
      "Train Epoch: 14 [180/347 (65%)]\tLoss: 0.051061\n",
      "Train Epoch: 14 [190/347 (68%)]\tLoss: 0.056381\n",
      "Train Epoch: 14 [200/347 (72%)]\tLoss: 0.054907\n",
      "Train Epoch: 14 [210/347 (76%)]\tLoss: 0.050080\n",
      "Train Epoch: 14 [220/347 (79%)]\tLoss: 0.031115\n",
      "Train Epoch: 14 [230/347 (83%)]\tLoss: 0.021664\n",
      "Train Epoch: 14 [240/347 (86%)]\tLoss: 0.036136\n",
      "Train Epoch: 14 [250/347 (90%)]\tLoss: 0.032487\n",
      "Train Epoch: 14 [260/347 (94%)]\tLoss: 0.027518\n",
      "Train Epoch: 14 [270/347 (97%)]\tLoss: 0.082555\n",
      "====> Epoch: 14 Average loss: 0.0390\n",
      "====> Test set loss: 0.0109\n",
      "Train Epoch: 15 [0/347 (0%)]\tLoss: 0.022409\n",
      "Train Epoch: 15 [10/347 (4%)]\tLoss: 0.078723\n",
      "Train Epoch: 15 [20/347 (7%)]\tLoss: 0.030282\n",
      "Train Epoch: 15 [30/347 (11%)]\tLoss: 0.030228\n",
      "Train Epoch: 15 [40/347 (14%)]\tLoss: 0.067902\n",
      "Train Epoch: 15 [50/347 (18%)]\tLoss: 0.060321\n",
      "Train Epoch: 15 [60/347 (22%)]\tLoss: 0.035522\n",
      "Train Epoch: 15 [70/347 (25%)]\tLoss: 0.032372\n",
      "Train Epoch: 15 [80/347 (29%)]\tLoss: 0.070698\n",
      "Train Epoch: 15 [90/347 (32%)]\tLoss: 0.110547\n",
      "Train Epoch: 15 [100/347 (36%)]\tLoss: 0.029841\n",
      "Train Epoch: 15 [110/347 (40%)]\tLoss: 0.036235\n",
      "Train Epoch: 15 [120/347 (43%)]\tLoss: 0.035334\n",
      "Train Epoch: 15 [130/347 (47%)]\tLoss: 0.027350\n",
      "Train Epoch: 15 [140/347 (50%)]\tLoss: 0.092292\n",
      "Train Epoch: 15 [150/347 (54%)]\tLoss: 0.073283\n",
      "Train Epoch: 15 [160/347 (58%)]\tLoss: 0.033691\n",
      "Train Epoch: 15 [170/347 (61%)]\tLoss: 0.043990\n",
      "Train Epoch: 15 [180/347 (65%)]\tLoss: 0.034594\n",
      "Train Epoch: 15 [190/347 (68%)]\tLoss: 0.087703\n",
      "Train Epoch: 15 [200/347 (72%)]\tLoss: 0.029327\n",
      "Train Epoch: 15 [210/347 (76%)]\tLoss: 0.026696\n",
      "Train Epoch: 15 [220/347 (79%)]\tLoss: 0.061010\n",
      "Train Epoch: 15 [230/347 (83%)]\tLoss: 0.056899\n",
      "Train Epoch: 15 [240/347 (86%)]\tLoss: 0.032849\n",
      "Train Epoch: 15 [250/347 (90%)]\tLoss: 0.033174\n",
      "Train Epoch: 15 [260/347 (94%)]\tLoss: 0.072392\n",
      "Train Epoch: 15 [270/347 (97%)]\tLoss: 0.067339\n",
      "====> Epoch: 15 Average loss: 0.0393\n",
      "====> Test set loss: 0.0105\n",
      "Train Epoch: 16 [0/347 (0%)]\tLoss: 0.048325\n",
      "Train Epoch: 16 [10/347 (4%)]\tLoss: 0.035892\n",
      "Train Epoch: 16 [20/347 (7%)]\tLoss: 0.035884\n",
      "Train Epoch: 16 [30/347 (11%)]\tLoss: 0.022556\n",
      "Train Epoch: 16 [40/347 (14%)]\tLoss: 0.022410\n",
      "Train Epoch: 16 [50/347 (18%)]\tLoss: 0.032572\n",
      "Train Epoch: 16 [60/347 (22%)]\tLoss: 0.047177\n",
      "Train Epoch: 16 [70/347 (25%)]\tLoss: 0.027006\n",
      "Train Epoch: 16 [80/347 (29%)]\tLoss: 0.032118\n",
      "Train Epoch: 16 [90/347 (32%)]\tLoss: 0.045729\n",
      "Train Epoch: 16 [100/347 (36%)]\tLoss: 0.042944\n",
      "Train Epoch: 16 [110/347 (40%)]\tLoss: 0.030091\n",
      "Train Epoch: 16 [120/347 (43%)]\tLoss: 0.065599\n",
      "Train Epoch: 16 [130/347 (47%)]\tLoss: 0.056064\n",
      "Train Epoch: 16 [140/347 (50%)]\tLoss: 0.085372\n",
      "Train Epoch: 16 [150/347 (54%)]\tLoss: 0.060279\n",
      "Train Epoch: 16 [160/347 (58%)]\tLoss: 0.078198\n",
      "Train Epoch: 16 [170/347 (61%)]\tLoss: 0.029286\n",
      "Train Epoch: 16 [180/347 (65%)]\tLoss: 0.033094\n",
      "Train Epoch: 16 [190/347 (68%)]\tLoss: 0.097133\n",
      "Train Epoch: 16 [200/347 (72%)]\tLoss: 0.026835\n",
      "Train Epoch: 16 [210/347 (76%)]\tLoss: 0.061898\n",
      "Train Epoch: 16 [220/347 (79%)]\tLoss: 0.079271\n",
      "Train Epoch: 16 [230/347 (83%)]\tLoss: 0.032331\n",
      "Train Epoch: 16 [240/347 (86%)]\tLoss: 0.039407\n",
      "Train Epoch: 16 [250/347 (90%)]\tLoss: 0.083385\n",
      "Train Epoch: 16 [260/347 (94%)]\tLoss: 0.053542\n",
      "Train Epoch: 16 [270/347 (97%)]\tLoss: 0.027626\n",
      "====> Epoch: 16 Average loss: 0.0388\n",
      "====> Test set loss: 0.0096\n",
      "Train Epoch: 17 [0/347 (0%)]\tLoss: 0.076801\n",
      "Train Epoch: 17 [10/347 (4%)]\tLoss: 0.083796\n",
      "Train Epoch: 17 [20/347 (7%)]\tLoss: 0.054619\n",
      "Train Epoch: 17 [30/347 (11%)]\tLoss: 0.031811\n",
      "Train Epoch: 17 [40/347 (14%)]\tLoss: 0.111818\n",
      "Train Epoch: 17 [50/347 (18%)]\tLoss: 0.043829\n",
      "Train Epoch: 17 [60/347 (22%)]\tLoss: 0.103046\n",
      "Train Epoch: 17 [70/347 (25%)]\tLoss: 0.035038\n",
      "Train Epoch: 17 [80/347 (29%)]\tLoss: 0.054590\n",
      "Train Epoch: 17 [90/347 (32%)]\tLoss: 0.100789\n",
      "Train Epoch: 17 [100/347 (36%)]\tLoss: 0.024326\n",
      "Train Epoch: 17 [110/347 (40%)]\tLoss: 0.066459\n",
      "Train Epoch: 17 [120/347 (43%)]\tLoss: 0.071177\n",
      "Train Epoch: 17 [130/347 (47%)]\tLoss: 0.053623\n",
      "Train Epoch: 17 [140/347 (50%)]\tLoss: 0.022727\n",
      "Train Epoch: 17 [150/347 (54%)]\tLoss: 0.039545\n",
      "Train Epoch: 17 [160/347 (58%)]\tLoss: 0.077621\n",
      "Train Epoch: 17 [170/347 (61%)]\tLoss: 0.081274\n",
      "Train Epoch: 17 [180/347 (65%)]\tLoss: 0.060177\n",
      "Train Epoch: 17 [190/347 (68%)]\tLoss: 0.061260\n",
      "Train Epoch: 17 [200/347 (72%)]\tLoss: 0.028115\n",
      "Train Epoch: 17 [210/347 (76%)]\tLoss: 0.024139\n",
      "Train Epoch: 17 [220/347 (79%)]\tLoss: 0.064744\n",
      "Train Epoch: 17 [230/347 (83%)]\tLoss: 0.102434\n",
      "Train Epoch: 17 [240/347 (86%)]\tLoss: 0.029591\n",
      "Train Epoch: 17 [250/347 (90%)]\tLoss: 0.054802\n",
      "Train Epoch: 17 [260/347 (94%)]\tLoss: 0.054294\n",
      "Train Epoch: 17 [270/347 (97%)]\tLoss: 0.024461\n",
      "====> Epoch: 17 Average loss: 0.0390\n",
      "====> Test set loss: 0.0094\n",
      "Train Epoch: 18 [0/347 (0%)]\tLoss: 0.041149\n",
      "Train Epoch: 18 [10/347 (4%)]\tLoss: 0.034883\n",
      "Train Epoch: 18 [20/347 (7%)]\tLoss: 0.032703\n",
      "Train Epoch: 18 [30/347 (11%)]\tLoss: 0.054622\n",
      "Train Epoch: 18 [40/347 (14%)]\tLoss: 0.027990\n",
      "Train Epoch: 18 [50/347 (18%)]\tLoss: 0.051863\n",
      "Train Epoch: 18 [60/347 (22%)]\tLoss: 0.110118\n",
      "Train Epoch: 18 [70/347 (25%)]\tLoss: 0.040986\n",
      "Train Epoch: 18 [80/347 (29%)]\tLoss: 0.026725\n",
      "Train Epoch: 18 [90/347 (32%)]\tLoss: 0.069398\n",
      "Train Epoch: 18 [100/347 (36%)]\tLoss: 0.095204\n",
      "Train Epoch: 18 [110/347 (40%)]\tLoss: 0.057366\n",
      "Train Epoch: 18 [120/347 (43%)]\tLoss: 0.101043\n",
      "Train Epoch: 18 [130/347 (47%)]\tLoss: 0.059232\n",
      "Train Epoch: 18 [140/347 (50%)]\tLoss: 0.058098\n",
      "Train Epoch: 18 [150/347 (54%)]\tLoss: 0.083366\n",
      "Train Epoch: 18 [160/347 (58%)]\tLoss: 0.027978\n",
      "Train Epoch: 18 [170/347 (61%)]\tLoss: 0.056430\n",
      "Train Epoch: 18 [180/347 (65%)]\tLoss: 0.026416\n",
      "Train Epoch: 18 [190/347 (68%)]\tLoss: 0.028871\n",
      "Train Epoch: 18 [200/347 (72%)]\tLoss: 0.047157\n",
      "Train Epoch: 18 [210/347 (76%)]\tLoss: 0.032131\n",
      "Train Epoch: 18 [220/347 (79%)]\tLoss: 0.030170\n",
      "Train Epoch: 18 [230/347 (83%)]\tLoss: 0.027141\n",
      "Train Epoch: 18 [240/347 (86%)]\tLoss: 0.053627\n",
      "Train Epoch: 18 [250/347 (90%)]\tLoss: 0.040758\n",
      "Train Epoch: 18 [260/347 (94%)]\tLoss: 0.099056\n",
      "Train Epoch: 18 [270/347 (97%)]\tLoss: 0.026277\n",
      "====> Epoch: 18 Average loss: 0.0389\n",
      "====> Test set loss: 0.0103\n",
      "Train Epoch: 19 [0/347 (0%)]\tLoss: 0.031621\n",
      "Train Epoch: 19 [10/347 (4%)]\tLoss: 0.024146\n",
      "Train Epoch: 19 [20/347 (7%)]\tLoss: 0.095673\n",
      "Train Epoch: 19 [30/347 (11%)]\tLoss: 0.033031\n",
      "Train Epoch: 19 [40/347 (14%)]\tLoss: 0.057177\n",
      "Train Epoch: 19 [50/347 (18%)]\tLoss: 0.076632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [60/347 (22%)]\tLoss: 0.100765\n",
      "Train Epoch: 19 [70/347 (25%)]\tLoss: 0.030518\n",
      "Train Epoch: 19 [80/347 (29%)]\tLoss: 0.072236\n",
      "Train Epoch: 19 [90/347 (32%)]\tLoss: 0.063315\n",
      "Train Epoch: 19 [100/347 (36%)]\tLoss: 0.037994\n",
      "Train Epoch: 19 [110/347 (40%)]\tLoss: 0.027756\n",
      "Train Epoch: 19 [120/347 (43%)]\tLoss: 0.058548\n",
      "Train Epoch: 19 [130/347 (47%)]\tLoss: 0.066994\n",
      "Train Epoch: 19 [140/347 (50%)]\tLoss: 0.053182\n",
      "Train Epoch: 19 [150/347 (54%)]\tLoss: 0.045257\n",
      "Train Epoch: 19 [160/347 (58%)]\tLoss: 0.044713\n",
      "Train Epoch: 19 [170/347 (61%)]\tLoss: 0.053094\n",
      "Train Epoch: 19 [180/347 (65%)]\tLoss: 0.051200\n",
      "Train Epoch: 19 [190/347 (68%)]\tLoss: 0.028865\n",
      "Train Epoch: 19 [200/347 (72%)]\tLoss: 0.028017\n",
      "Train Epoch: 19 [210/347 (76%)]\tLoss: 0.030419\n",
      "Train Epoch: 19 [220/347 (79%)]\tLoss: 0.032222\n",
      "Train Epoch: 19 [230/347 (83%)]\tLoss: 0.077111\n",
      "Train Epoch: 19 [240/347 (86%)]\tLoss: 0.077085\n",
      "Train Epoch: 19 [250/347 (90%)]\tLoss: 0.028850\n",
      "Train Epoch: 19 [260/347 (94%)]\tLoss: 0.025925\n",
      "Train Epoch: 19 [270/347 (97%)]\tLoss: 0.027694\n",
      "====> Epoch: 19 Average loss: 0.0392\n",
      "====> Test set loss: 0.0104\n",
      "Train Epoch: 20 [0/347 (0%)]\tLoss: 0.024663\n",
      "Train Epoch: 20 [10/347 (4%)]\tLoss: 0.042456\n",
      "Train Epoch: 20 [20/347 (7%)]\tLoss: 0.031432\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ab8eca6be6ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-5cc6a149bd02>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;36m100.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             loss.data.item() / len(data)))\n\u001b[0m\u001b[0;32m     29\u001b[0m     print('====> Epoch: {} Average loss: {:.4f}'.format(\n\u001b[0;32m     30\u001b[0m         \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mGWAS\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[1;31m# newlines imply flush in subprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mGWAS\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mGWAS\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    398\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[0;32m    399\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mGWAS\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    \n",
    "    \n",
    "    sample = torch.randn(64, ZDIMS).to(device)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    sample = model.decode(sample).cpu()\n",
    "    \n",
    "    \n",
    "    #save_image(sample.data.view(64, 1, 28, 28),\n",
    "              #'results/sample_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 Epochs each w/ batch size of 1\n",
    "w/ 10 zdims and 1000 hidden layer: Test set loss: 0.0097\n",
    "w/ 3000 zdims and 5000 hidden layers: Test set loss: 0.0136\n",
    "w/ 1000 zdims and 3000 hidden layers: Test set loss: like .02\n",
    "w/ 300 zdims and 1000 hidden layers: Test set loss: 0.0333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
